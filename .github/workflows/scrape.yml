name: Scrape → Normalize → Publish

on:
  workflow_dispatch:        # lanzar a mano desde la pestaña Actions
  schedule:
    - cron: "0 */6 * * *"   # cada 6 h (UTC). Madrid = UTC+2 en verano, +1 en invierno.

permissions:
  contents: write           # permite commitear cambios con GITHUB_TOKEN

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r scraper/requirements.txt

      # Ejecuta tus scrapers. Cambia/añade líneas según tus archivos.
      - name: Run scrapers (per-source)
        run: |
          python scraper/rss_to_csv.py || echo "rss_to_csv falló pero seguimos"
          python scraper/tsmc_latest.py || echo "tsmc_latest falló pero seguimos"

      - name: Normalize & merge
        run: |
          python scraper/normalize.py

      - name: Commit changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore: refresh news"
          file_pattern: |
            data/*.csv
            data/*.json
